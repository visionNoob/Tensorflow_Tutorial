{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 - Logistic regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visionNoob/Tensorflow_Tutorial/blob/master/Day_1/2%20-%20Logistic%20regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okEiFJLI4k5M",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gEndPDUNEe-H",
        "outputId": "8d3e4bac-4e72-4fb0-a02d-593237ee5b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "tf.enable_eager_execution()\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dRqCpkpdMdTQ"
      },
      "source": [
        "## Make a dataset for Logistic Regression\n",
        "\n",
        "### Logistic Regression을 위한 Dataset을 임의로 만들어 봅시다.\n",
        "\n",
        "* 2가지 위치에 몰려있는 데이터\n",
        "* 테스트를 위한 빨간색 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9yre_ERVEma8",
        "outputId": "10027f22-72d6-4e89-c6b2-e8be152c0724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "x_train = [[1., 1.2],\n",
        "          [2., 1.5],\n",
        "          [3., 1.1],\n",
        "          [4., 3.],\n",
        "          [5., 2.7],\n",
        "          [6., 2.5]]\n",
        "y_train = [[0.],\n",
        "          [0.],\n",
        "          [0.],\n",
        "          [1.],\n",
        "          [1.],\n",
        "          [1.]]\n",
        "\n",
        "x_test = [[3.5,2.15]]\n",
        "y_test = [[1.]]\n",
        "\n",
        "x1 = [x[0] for x in x_train]\n",
        "x2 = [x[1] for x in x_train]\n",
        "\n",
        "colors = [int(y[0] % 3) for y in y_train]\n",
        "plt.scatter(x1,x2, c=colors , marker='^')\n",
        "plt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na3HQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz_5ek6x4k5X",
        "colab_type": "text"
      },
      "source": [
        "## tf.data.Dataset\n",
        "* 데이터를 관리해주기위한 tf function\n",
        "* 각 데이터의 필요 기능들을 지원해준다.\n",
        "* 데이터셋 크기가 클 경우에 메모리에 나눠올리는 기능을 지원"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MxddblPApI8v",
        "outputId": "cb377058-aeaa-4b8c-c925-a05d758dbf10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).batch(len(x_train))\n",
        "\n",
        "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "print(W, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "<tf.Variable 'weight:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[ 0.69984436],\n",
            "       [-1.9253724 ]], dtype=float32)> <tf.Variable 'bias:0' shape=(1,) dtype=float32, numpy=array([-0.92719346], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BYPKT6To56Iv"
      },
      "source": [
        "## Sigmoid 함수를 가설로 선언합니다\n",
        "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
        "\n",
        "## $$\n",
        "\\begin{align}\n",
        "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LFAWvdar8PP-",
        "outputId": "ee083bab-84d7-4c61-b020-b745ac4b0c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "def logistic_regression(features):\n",
        "    hypothesis  = tf.div(1., 1. + tf.exp(-(tf.matmul(features, W) + b)))\n",
        "    return hypothesis\n",
        "\n",
        "print(logistic_regression(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Neg in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Exp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "WARNING:tensorflow:From <ipython-input-4-47df1c591a10>:2: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "tf.Tensor(\n",
            "[[0.07325065]\n",
            " [0.08199359]\n",
            " [0.2797766 ]\n",
            " [0.01976396]\n",
            " [0.06745372]\n",
            " [0.1763089 ]], shape=(6, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXHVNZ6W8V83"
      },
      "source": [
        "## 가설을 검증할 Cost 함수를 정의합니다\n",
        "$$\n",
        "\\begin{align}\n",
        "cost(h(x),y) & = −log(h(x))  &  if :  &  y=1 \\\\\\\\\\\n",
        "cost(h(x),y) & = -log(1−h(x))  &  if :  &  y=0\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "### 두 식을 한번에 쓰게되면,\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oxIgE6nt8zvR",
        "colab": {}
      },
      "source": [
        "def loss_fn(hypothesis, labels):\n",
        "    cost = -tf.reduce_mean(labels * tf.log(hypothesis) + \\\n",
        "                           (1 - labels) * tf.log(1 - hypothesis))\n",
        "    return cost\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8xmYMVq65vFd",
        "outputId": "d9015cc6-4ac4-4249-9e6e-711cb8156b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 5000\n",
        "\n",
        "for step in range(epochs):\n",
        "  for features, labels in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = loss_fn(logistic_regression(features),labels)\n",
        "      grads = tape.gradient(loss_value, [W,b])\n",
        "      optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
        "      if step % 100 == 0:\n",
        "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),labels)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Log in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Mean in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Tile in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Reciprocal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Shape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op BroadcastGradientArgs in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sum in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AddN in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ResourceApplyGradientDescent in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Iter: 0, Loss: 1.4684\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Iter: 100, Loss: 1.0124\n",
            "Iter: 200, Loss: 0.7776\n",
            "Iter: 300, Loss: 0.6677\n",
            "Iter: 400, Loss: 0.6147\n",
            "Iter: 500, Loss: 0.5875\n",
            "Iter: 600, Loss: 0.5726\n",
            "Iter: 700, Loss: 0.5639\n",
            "Iter: 800, Loss: 0.5583\n",
            "Iter: 900, Loss: 0.5544\n",
            "Iter: 1000, Loss: 0.5515\n",
            "Iter: 1100, Loss: 0.5491\n",
            "Iter: 1200, Loss: 0.5469\n",
            "Iter: 1300, Loss: 0.5449\n",
            "Iter: 1400, Loss: 0.5430\n",
            "Iter: 1500, Loss: 0.5412\n",
            "Iter: 1600, Loss: 0.5394\n",
            "Iter: 1700, Loss: 0.5376\n",
            "Iter: 1800, Loss: 0.5359\n",
            "Iter: 1900, Loss: 0.5341\n",
            "Iter: 2000, Loss: 0.5324\n",
            "Iter: 2100, Loss: 0.5307\n",
            "Iter: 2200, Loss: 0.5290\n",
            "Iter: 2300, Loss: 0.5273\n",
            "Iter: 2400, Loss: 0.5256\n",
            "Iter: 2500, Loss: 0.5239\n",
            "Iter: 2600, Loss: 0.5222\n",
            "Iter: 2700, Loss: 0.5205\n",
            "Iter: 2800, Loss: 0.5188\n",
            "Iter: 2900, Loss: 0.5171\n",
            "Iter: 3000, Loss: 0.5155\n",
            "Iter: 3100, Loss: 0.5138\n",
            "Iter: 3200, Loss: 0.5122\n",
            "Iter: 3300, Loss: 0.5105\n",
            "Iter: 3400, Loss: 0.5089\n",
            "Iter: 3500, Loss: 0.5073\n",
            "Iter: 3600, Loss: 0.5056\n",
            "Iter: 3700, Loss: 0.5040\n",
            "Iter: 3800, Loss: 0.5024\n",
            "Iter: 3900, Loss: 0.5008\n",
            "Iter: 4000, Loss: 0.4992\n",
            "Iter: 4100, Loss: 0.4976\n",
            "Iter: 4200, Loss: 0.4960\n",
            "Iter: 4300, Loss: 0.4944\n",
            "Iter: 4400, Loss: 0.4929\n",
            "Iter: 4500, Loss: 0.4913\n",
            "Iter: 4600, Loss: 0.4897\n",
            "Iter: 4700, Loss: 0.4882\n",
            "Iter: 4800, Loss: 0.4866\n",
            "Iter: 4900, Loss: 0.4851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ci-nHblj--z9",
        "colab": {}
      },
      "source": [
        "def accuracy_fn(hypothesis, labels):\n",
        "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YANtydPI6-sl",
        "outputId": "19d6f6b7-b367-4022-c71c-b9f70d11e7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
        "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op Greater in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Testset Accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-d28dms4k5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}