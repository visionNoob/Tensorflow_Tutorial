{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05 - XOR problem_linear case.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visionNoob/Tensorflow_Tutorial/blob/master/Day_2/05%20-%20XOR%20problem_linear%20case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9JutkdoS4X-A",
        "outputId": "92c38a97-a97c-44e6-88b9-d2fa53c26527",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CMX1E1gY2GJy"
      },
      "source": [
        "# XOR Problem\n",
        "\n",
        "* XOR 로 표시되는 정보를 구분해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NCbBvoYl2CKv",
        "colab": {}
      },
      "source": [
        "x_data = [[0., 0.],\n",
        "          [0., 1.],\n",
        "          [1., 0.],\n",
        "          [1., 1.]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f5941339-d8e6-438c-910b-74914ff46173",
        "id": "v8WPLX2M2Pwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "y_data = [[0.],\n",
        "          [1.],\n",
        "          [1.],\n",
        "          [0.]]\n",
        "\n",
        "plt.scatter(x_data[0][0],x_data[0][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[3][0],x_data[3][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[1][0],x_data[1][1], c='blue' , marker='^')\n",
        "plt.scatter(x_data[2][0],x_data[2][1], c='blue' , marker='^')\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QlyhDb1a2RZN"
      },
      "source": [
        "# Dataset 준비\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I4Inx8z-2Edf",
        "outputId": "ab1a0f68-2cf7-47a6-9673-8b277e2536ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-_m-9SeSWufJ"
      },
      "source": [
        "# Multi-layer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fTdFrE40Dx1W",
        "outputId": "adef6b96-f770-44ff-af96-3db418c08568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "W1 = tf.Variable(tf.random_uniform([2, 5], -1.0, 1.0), name='weight1')\n",
        "W2 = tf.Variable(tf.random_uniform([5, 4], -1.0, 1.0), name='weight2')\n",
        "W3 = tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0), name='weight3')\n",
        "\n",
        "b1 = tf.Variable(tf.zeros([5]), name='bias1')\n",
        "b2 = tf.Variable(tf.zeros([4]), name='bias2')\n",
        "b3 = tf.Variable(tf.zeros([1]), name='bias3')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Reshape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8_Nfv3IsWzeS"
      },
      "source": [
        "## Layers 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q4TzyRhLDy4r",
        "colab": {}
      },
      "source": [
        "def neural_net(features):\n",
        "    layer1 = tf.sigmoid(tf.matmul(features, W1) + b1)\n",
        "    layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "    hypothesis = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
        "    \n",
        "    return hypothesis\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVZXfF3xV7mu",
        "colab_type": "code",
        "outputId": "6f494673-3107-4fab-9a4f-20c482809b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "W_linear_1 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0), name='weight1')\n",
        "b_linear_1 = tf.Variable(tf.zeros([1]), name='bias1')\n",
        "\n",
        "def linear_model(features):\n",
        "    hypothesis = tf.sigmoid(tf.matmul(features, W_linear_1) + b_linear_1)\n",
        "    return hypothesis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pljhbXSIW2A0"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w6Ba-vn6GK5P",
        "colab": {}
      },
      "source": [
        "def loss_fn(hypothesis, labels):\n",
        "    cost = -tf.reduce_mean(labels * tf.log(hypothesis) + (1 - labels) * tf.log(1 - hypothesis))\n",
        "    return cost\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IexpBSeGnd6",
        "colab": {}
      },
      "source": [
        "def grad(hypothesis, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss_fn(linear_model(features),labels)\n",
        "    return tape.gradient(loss_value, [W1, W2, W3, b1, b2, b3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNZBnLVsW8HE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad_linear(hypothesis, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss_fn(linear_model(features),labels)\n",
        "    return tape.gradient(loss_value, [W_linear_1, b_linear_1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1SOZXl72Pwv",
        "colab_type": "text"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V0Orlau1GfFA",
        "outputId": "fa11f36b-0fcc-494e-da44-40fb7ba6434f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "EPOCHS = 10000\n",
        "\n",
        "for step in range(EPOCHS):\n",
        "    for features, labels  in dataset:\n",
        "        #grads = grad(neural_net(features), labels)\n",
        "        grads = grad_linear(linear_model(features), labels)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W_linear_1, b_linear_1]))\n",
        "        if step % 1000 == 0:\n",
        "            #print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(neural_net(features),labels)))\n",
        "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(linear_model(features),labels)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op Log in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Neg in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Tile in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Reciprocal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Shape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op BroadcastGradientArgs in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Sum in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AddN in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op SigmoidGrad in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ResourceApplyGradientDescent in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Iter: 0, Loss: 0.7041\n",
            "Iter: 1000, Loss: 0.6931\n",
            "Iter: 2000, Loss: 0.6931\n",
            "Iter: 3000, Loss: 0.6931\n",
            "Iter: 4000, Loss: 0.6931\n",
            "Iter: 5000, Loss: 0.6931\n",
            "Iter: 6000, Loss: 0.6931\n",
            "Iter: 7000, Loss: 0.6931\n",
            "Iter: 8000, Loss: 0.6931\n",
            "Iter: 9000, Loss: 0.6931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9CHtdCaFGU7z",
        "colab": {}
      },
      "source": [
        "def accuracy_fn(hypothesis, labels):\n",
        "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gR4Sz2doGeEr",
        "outputId": "b23dd882-400c-41a8-ce78-9fd66437a9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test_acc = accuracy_fn(neural_net(x_data),y_data)\n",
        "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op Greater in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Testset Accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hLLgI98kGy0m",
        "outputId": "35607811-e86f-4215-c170-d527877504b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test_acc = accuracy_fn(linear_model(x_data),y_data)\n",
        "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op Greater in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Testset Accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ii8LOO1aD6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}